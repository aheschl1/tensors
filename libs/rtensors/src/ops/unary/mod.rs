use crate::{
    backend::Backend,
    core::{
        TensorView, TensorViewMut, primitives::TensorBase, primops::{Exp, InvExp, SquareRoot}, tensor::{AsTensor, AsViewMut}, value::{TensorValue, WeightValue}
    },
};


macro_rules! specify_unary_op_template {
    (
        $(
            ($name:ident) $op:ident $(where T: $first:path $(, $extra:path)*)?;
        )+
    ) => {

        paste::paste! {

            pub trait InplaceUnaryOp<T: TensorValue, B: Backend> {
                $(
                    fn [<apply_ $op>](&mut self)
                    where 
                    $(
                        T: $first $(+ $extra)*
                    )?;
                )+

            }

            
            pub trait UnaryOp<T: TensorValue, B: Backend> {
                $(
                    fn $op(&self) -> TensorBase<T, B>
                    where
                    $(
                        T: $first $(+ $extra)*
                    )?;
                )+
            }


            $(

                pub trait $name<T: TensorValue, B: Backend> {
                    fn [<$op _inplace>](&mut self)
                    where
                     $(
                        T: $first $(+ $extra)*
                    )?
                    ;
                }

                impl<T: TensorValue, B: Backend, V: AsViewMut<T, B>> $name<T, B> for V {
                    fn [<$op _inplace>](&mut self)
                    where
                     $(
                        T: $first $(+ $extra)*
                    )?
                    {
                        let view = self.view_mut();
                        if let Err(e) = view.backend.[<apply_ $op>](view.buf, &view.meta) {
                            panic!("Failed to apply abs: {}", e);
                        }
                    }
                }

              
            )+



            impl<T: TensorValue, B: Backend, V: AsViewMut<T, B>> InplaceUnaryOp<T, B> for V
            {
                $(
                    fn [<apply_ $op>](&mut self)
                    where
                    $(
                        T: $first $(+ $extra)*
                    )?
                    {
                        self.[<$op _inplace>]();
                    }
                )+
            }

            
            impl<T: TensorValue, B: Backend, V: AsTensor<T, B>> UnaryOp<T, B> for V {
                $(
                    fn $op(&self) -> TensorBase<T, B>
                    where
                    $(
                        T: $first $(+ $extra)*
                    )?
                    {
                        let mut result = self.owned();
                        result.[<apply_ $op>]();
                        result
                    }
                )+
            }
           
        }
        
    };
}

specify_unary_op_template! {
    (Abs) abs;
    (Relu) relu;
    (Sigmoid) sigmoid where T: InvExp;
    (Tanh) tanh where T: Exp, InvExp;
    (Sqrt) sqrt where T: SquareRoot;
    (Negate) neg where T: std::ops::Neg<Output = T>;
    (NatLog) ln where T: WeightValue;
    (ExpM1) expm1 where T: Exp;
    (Ln1p) ln1p where T: WeightValue;
    (Floor) floor where T: WeightValue;
    (Ceil) ceil where T: WeightValue;
    (Round) round where T: WeightValue;
    (Trunc) trunc where T: WeightValue;
}

impl<T, B> std::ops::Neg for TensorBase<T, B>
where
    T: TensorValue + std::ops::Neg<Output = T>,
    B: Backend,
{
    type Output = TensorBase<T, B>;

    fn neg(self) -> Self::Output {
        let mut result = self.owned();
        result.neg_inplace();
        result
    }
}

impl<'a, T, B> std::ops::Neg for TensorView<'a, T, B>
where
    T: TensorValue + std::ops::Neg<Output = T>,
    B: Backend,
{
    type Output = TensorBase<T, B>;

    fn neg(self) -> Self::Output {
        let mut result = self.owned();
        result.neg_inplace();
        result
    }
}

impl<'a, T, B> std::ops::Neg for TensorViewMut<'a, T, B>
where
    T: TensorValue + std::ops::Neg<Output = T>,
    B: Backend,
{
    type Output = TensorBase<T, B>;

    fn neg(self) -> Self::Output {
        let mut result = self.owned();
        result.neg_inplace();
        result
    }
}


#[cfg(test)]
mod tests {
    use crate::{
        backend::cpu::Cpu,
        ops::unary::{Ceil, ExpM1, Floor, Ln1p, NatLog, Negate, Relu, Round, Sigmoid, Sqrt, Tanh, Trunc},
        testing::{unary_assert_1d_strided, unary_assert_contiguous, unary_assert_nd_strided},
    };

    #[test]
    fn test_unary_negate_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>([1.0, 1.0], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_negate_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>([1.0, 1.0, 1.0], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_negate_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>([1.0; 16], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_relu_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>([-1.0, 1.0], |f| f.max(0.0), Relu::relu_inplace);
    }

    #[test]
    fn test_unary_relu_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>(
            [-1.0, 1.0, -1.0],
            |f| f.max(0.0),
            |f| f.relu_inplace(),
        );
    }

    #[test]
    fn test_unary_relu_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>(
            [
                -1.0, 1.0, 0.0, 2.0, 1.0, 2.3, -0.3, 0.4, 0.0, -0.3, 0.4, 0.5, -0.2, 0.1, 0.2, -0.5,
            ],
            |f| f.max(0.0),
            |f| f.relu_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>(
            [1.0, 1.0],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>(
            [1.0, 1.0, 1.0],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>(
            [1.0; 16],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>(
            [1.0, 1.0],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>(
            [1.0, 1.0, 1.0],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>(
            [1.0; 16],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_sqrt_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>([1.0; 16], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_sqrt_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>(
            [1.0, 1.0, 1.0],
            |f| f.sqrt(),
            |f| f.sqrt_inplace(),
        );
    }

    #[test]
    fn test_unary_sqrt_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>([1.0; 2], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_ln_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cpu>([1.0; 16], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cpu>(
            [1.0, 1.0, 1.0],
            |f| f.ln(),
            |f| f.ln_inplace(),
        );
    }

    #[test]
    fn test_unary_ln_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cpu>([1.0; 2], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([1.5; 16], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [1.5, 1.5, 1.5],
            |f| f.ln(),
            |f| f.ln_inplace(),
        );
    }

    #[test]
    fn test_unary_ln_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([1.5; 2], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_expm1_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([1.5; 16], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_expm1_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [1.5, 1.5, 1.5],
            |f| f.exp_m1(),
            |f| f.expm1_inplace(),
        );
    }

    #[test]
    fn test_unary_expm1_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([1.5; 2], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_ln1p_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([0.5; 16], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_ln1p_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [0.5, 0.5, 0.5],
            |f| f.ln_1p(),
            |f| f.ln1p_inplace(),
        );
    }

    #[test]
    fn test_unary_ln1p_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([0.5; 2], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_floor_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([1.7; 16], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_floor_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [1.7, 2.3, 3.9],
            |f| f.floor(),
            |f| f.floor_inplace(),
        );
    }

    #[test]
    fn test_unary_floor_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([1.7, 2.3], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_ceil_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([1.3; 16], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_ceil_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [1.3, 2.7, 3.1],
            |f| f.ceil(),
            |f| f.ceil_inplace(),
        );
    }

    #[test]
    fn test_unary_ceil_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([1.3, 2.7], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_round_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([1.4; 16], |f| f.round(), |f| f.round_inplace());
    }

    #[test]
    fn test_unary_round_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [1.4, 2.6, 3.5],
            |f| f.round(),
            |f| f.round_inplace(),
        );
    }

    #[test]
    fn test_unary_round_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([1.4, 2.6], |f| f.round(), |f| f.round_inplace());
    }

    #[test]
    fn test_unary_trunc_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cpu>([-1.4; 16], |f| f.trunc(), |f| f.trunc_inplace());
    }

    #[test]
    fn test_unary_trunc_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cpu>(
            [-1.4, 2.6, 3.5],
            |f| f.trunc(),
            |f| f.trunc_inplace(),
        );
    }

    #[test]
    fn test_unary_trunc_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cpu>([-1.4, 2.6], |f| f.trunc(), |f| f.trunc_inplace());
    }
}

#[cfg(all(test, feature = "cuda"))]
mod cuda_tests {
    use crate::{
        backend::cuda::Cuda,
        core::{
            primitives::{CudaTensor, TensorBase},
            tensor::{AsTensor, TensorAccess, TensorAccessMut},
            Tensor,
        },
        ops::unary::{Abs, Ceil, ExpM1, Floor, Ln1p, NatLog, Negate, Relu, Round, Sigmoid, Sqrt as _, Tanh, Trunc},
        testing::{
            test_with_contiguous_2_elem_tensor, unary_assert_1d_strided, unary_assert_contiguous,
            unary_assert_nd_strided,
        },
    };

    #[test]
    fn test_unary_negate_continous_cuda() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.0, 1.0], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_negate_1d_strided_cuda() {
        unary_assert_1d_strided::<f64, _, _, Cuda>([1.0, 1.0, 1.0], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_negate_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.0; 16], std::ops::Neg::neg, |f| {
            f.neg_inplace()
        });
    }

    #[test]
    fn test_unary_abs_continous_cuda() {
        unary_assert_contiguous::<f64, _, _, Cuda>([-1.0, 1.3], |f| f.abs(), |f| f.abs_inplace());
    }

    #[test]
    fn test_unary_abs_1d_strided_cuda() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.0, -1.0, 3.0],
            |f| f.abs(),
            |f| f.abs_inplace(),
        );
    }

    #[test]
    fn test_unary_abs_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([-1.0; 16], |f| f.abs(), |f| f.abs_inplace());
    }

    #[test]
    fn test_unary_relu_contiguous_cuda() {
        unary_assert_contiguous::<f64, _, _, Cuda>([-1.0, 1.0], |f| f.max(0.0), Relu::relu_inplace);
    }

    #[test]
    fn test_unary_relu_1d_strided_cuda() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [-1.0, 1.0, -1.0],
            |f| f.max(0.0),
            |f| f.relu_inplace(),
        );
    }

    #[test]
    fn test_unary_relu_nd_strided_cuda() {
        unary_assert_nd_strided::<f64, _, _, Cuda>(
            [
                -1.0, 1.0, 0.0, 2.0, 1.0, 2.3, -0.3, 0.4, 0.0, -0.3, 0.4, 0.5, -0.2, 0.1, 0.2, -0.5,
            ],
            |f| f.max(0.0),
            |f| f.relu_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_contiguous_cuda() {
        unary_assert_contiguous::<f64, _, _, Cuda>(
            [1.0, 1.0],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_1d_strided_cuda() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.0, 1.0, 1.0],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_sigmoid_nd_strided_cuda() {
        unary_assert_nd_strided::<f64, _, _, Cuda>(
            [1.0; 16],
            |f| 1. / (1. + (-f).exp()),
            |f| f.sigmoid_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_contiguous_cuda() {
        unary_assert_contiguous::<f64, _, _, Cuda>(
            [1.0, 1.0],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_1d_strided_cuda() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.0, 1.0, 1.0],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_tanh_nd_strided_cuda() {
        unary_assert_nd_strided::<f64, _, _, Cuda>(
            [1.0; 16],
            |f| (f.exp() - (-f).exp()) / (f.exp() + (-f).exp()),
            |f| f.tanh_inplace(),
        );
    }

    #[test]
    fn test_unary_sqrt_nd_strided() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.0; 16], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_sqrt_1d_strided() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.0, 1.0, 1.0],
            |f| f.sqrt(),
            |f| f.sqrt_inplace(),
        );
    }

    #[test]
    fn test_unary_sqrt_contiguous() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.0; 2], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_sqrt_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.0; 16], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_sqrt_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.0, 1.0, 1.0],
            |f| f.sqrt(),
            |f| f.sqrt_inplace(),
        );
    }

    #[test]
    fn test_unary_sqrt_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([1.0; 2], |f| f.sqrt(), |f| f.sqrt_inplace());
    }

    #[test]
    fn test_unary_ln_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.0; 16], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.0, 1.0, 1.0],
            |f| f.ln(),
            |f| f.ln_inplace(),
        );
    }

    #[test]
    fn test_unary_ln_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([1.0; 2], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.5; 16], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_ln_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.5, 1.1, 1.5],
            |f| f.ln(),
            |f| f.ln_inplace(),
        );
    }

    #[test]
    fn test_unary_ln_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.5; 2], |f| f.ln(), |f| f.ln_inplace());
    }

    #[test]
    fn test_unary_expm1_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.5; 16], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_expm1_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.5, 1.1, 1.5],
            |f| f.exp_m1(),
            |f| f.expm1_inplace(),
        );
    }

    #[test]
    fn test_unary_expm1_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.5; 2], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_expm1_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.5; 16], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_expm1_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.5, 1.1, 1.5],
            |f| f.exp_m1(),
            |f| f.expm1_inplace(),
        );
    }

    #[test]
    fn test_unary_expm1_contiguous_f32() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.5; 2], |f| f.exp_m1(), |f| f.expm1_inplace());
    }

    #[test]
    fn test_unary_ln1p_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([0.5; 16], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_ln1p_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [0.5, 0.1, 0.5],
            |f| f.ln_1p(),
            |f| f.ln1p_inplace(),
        );
    }

    #[test]
    fn test_unary_ln1p_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([0.5; 2], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_ln1p_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([0.5; 16], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_ln1p_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [0.5, 0.1, 0.5],
            |f| f.ln_1p(),
            |f| f.ln1p_inplace(),
        );
    }

    #[test]
    fn test_unary_ln1p_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([0.5; 2], |f| f.ln_1p(), |f| f.ln1p_inplace());
    }

    #[test]
    fn test_unary_floor_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.7; 16], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_floor_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.7, 2.3, 3.9],
            |f| f.floor(),
            |f| f.floor_inplace(),
        );
    }

    #[test]
    fn test_unary_floor_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.7, 2.3], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_floor_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.7; 16], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_floor_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.7, 2.3, 3.9],
            |f| f.floor(),
            |f| f.floor_inplace(),
        );
    }

    #[test]
    fn test_unary_floor_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([1.7, 2.3], |f| f.floor(), |f| f.floor_inplace());
    }

    #[test]
    fn test_unary_ceil_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.3; 16], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_ceil_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.3, 2.7, 3.1],
            |f| f.ceil(),
            |f| f.ceil_inplace(),
        );
    }

    #[test]
    fn test_unary_ceil_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.3, 2.7], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_ceil_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.3; 16], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_ceil_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.3, 2.7, 3.1],
            |f| f.ceil(),
            |f| f.ceil_inplace(),
        );
    }

    #[test]
    fn test_unary_ceil_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([1.3, 2.7], |f| f.ceil(), |f| f.ceil_inplace());
    }

    #[test]
    fn test_unary_round_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([1.3; 16], |f| f.round(), |f| {
            f.round_inplace()
        });
    }

    #[test]
    fn test_unary_round_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [1.3, 2.7, 3.1],
            |f| f.round(),
            |f| f.round_inplace(),
        );
    }

    #[test]
    fn test_unary_round_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([1.3, 2.7], |f| f.round(), |f| {
            f.round_inplace()
        });
    }

    #[test]
    fn test_unary_round_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([1.3; 16], |f| f.round(), |f| {
            f.round_inplace()
        });
    }

    #[test]
    fn test_unary_round_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [1.3, 2.7, 3.1],
            |f| f.round(),
            |f| f.round_inplace(),
        );
    }

    #[test]
    fn test_unary_round_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([-1.3, 2.7], |f| f.round(), |f| {
            f.round_inplace()
        });
    }

    #[test]
    fn test_unary_trunc_nd_strided_f64() {
        unary_assert_nd_strided::<f64, _, _, Cuda>([-1.3; 16], |f| f.trunc(), |f| {
            f.trunc_inplace()
        });
    }

    #[test]
    fn test_unary_trunc_1d_strided_f64() {
        unary_assert_1d_strided::<f64, _, _, Cuda>(
            [-1.3, 2.7, 3.1],
            |f| f.trunc(),
            |f| f.trunc_inplace(),
        );
    }

    #[test]
    fn test_unary_trunc_contiguous_f64() {
        unary_assert_contiguous::<f64, _, _, Cuda>([-1.3, 2.7], |f| f.trunc(), |f| {
            f.trunc_inplace()
        });
    }

    #[test]
    fn test_unary_trunc_nd_strided_f32() {
        unary_assert_nd_strided::<f32, _, _, Cuda>([-1.3; 16], |f| f.trunc(), |f| {
            f.trunc_inplace()
        });
    }

    #[test]
    fn test_unary_trunc_1d_strided_f32() {
        unary_assert_1d_strided::<f32, _, _, Cuda>(
            [-1.3, 2.7, 3.1],
            |f| f.trunc(),
            |f| f.trunc_inplace(),
        );
    }

    #[test]
    fn test_unary_trunc_contiguous_f32() {
        unary_assert_contiguous::<f32, _, _, Cuda>([-1.3, 2.7], |f| f.trunc(), |f| {
            f.trunc_inplace()
        });
    }
}

#[cfg(all(test, feature = "remote"))]
mod remote_tests {
    use std::{sync::OnceLock, thread};

    use crate::{
        backend::{
            remote::{client::RemoteBackend, get_backend_default, server::RemoteServer},
            Backend,
        },
        core::{
            primitives::{RemoteTensor, TensorBase},
            tensor::TensorError,
            value::TensorValue,
            MetaTensor, Shape,
        },
    };

    // Lazy static backend shared across all tests
    static BACKEND: OnceLock<RemoteBackend> = OnceLock::new();

    fn get_backend() -> RemoteBackend {
        BACKEND
            .get_or_init(|| {
                // Start the server
                let mut server = RemoteServer::new("127.0.0.1".parse().unwrap(), 7878);
                thread::spawn(move || {
                    let _ = server.serve();
                });
                thread::sleep(std::time::Duration::from_millis(10));

                // Create and connect the backend
                let backend = get_backend_default().unwrap();

                backend
            })
            .clone()
    }

    fn make_remote_tensor<T: TensorValue>(
        buf: Vec<T>,
        shape: impl Into<Shape>,
    ) -> Result<RemoteTensor<T>, TensorError> {
        let shape: Shape = shape.into();
        let buf_len = buf.len();
        let expected_len: usize = shape.iter().product();

        if buf_len != expected_len {
            return Err(TensorError::InvalidShape(format!(
                "Element count mismatch: shape implies {} elements, but buffer has {} elements",
                expected_len, buf_len
            )));
        }

        let backend = get_backend();
        let buffer = backend.alloc_from_slice(buf.into())?;
        let stride = crate::core::shape_to_stride(&shape);

        // Clone the backend for this tensor
        let tensor_backend = backend.clone();
        drop(backend); // Release the lock

        Ok(TensorBase::from_parts(
            tensor_backend,
            buffer,
            MetaTensor::new(shape, stride, 0),
        ))
    }

    #[test]
    fn test_remote_negate() {
        let tensor: TensorBase<f32, RemoteBackend> =
            make_remote_tensor(vec![1.0f32, -2.0, 3.0], (3,)).unwrap();
        let negated = -tensor;

        let expected = make_remote_tensor(vec![-1.0f32, 2.0, -3.0], (3,)).unwrap();
        assert_eq!(negated.cpu().unwrap(), expected.cpu().unwrap());
    }
}
